# æª”æ¡ˆ: main_scraper.py (æ•´é»å¾ªç’°ç›£è½ç‰ˆæœ¬)

from datetime import datetime, time as dt_time
import os
import undetected_chromedriver as uc
import time
import json 
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException 
import pandas as pd
import re
from selenium.common.exceptions import WebDriverException
import subprocess 
from dotenv import load_dotenv

from model.auction_item import AuctionItem

load_dotenv() 

# æ›¿æ›æˆä½ çš„å¯¦éš›å¸³è™Ÿå’Œå¯†ç¢¼
YOUR_USERNAME = os.getenv("AUCTION_USERNAME") 
YOUR_ID = os.getenv("AUCTION_ID")


# ----------------- æ ¸å¿ƒç­‰å¾…é‚è¼¯ -----------------
def element_has_non_empty_value(locator):
    """è‡ªå®šç¾© EC æ¢ä»¶ï¼šç­‰å¾…å…ƒç´ çš„ 'value' å±¬æ€§è®Šç‚ºéç©º (ç”¨æ–¼ Turnstile Token)ã€‚"""
    def _predicate(driver):
        try:
            element = driver.find_element(*locator)
            element_value = element.get_attribute("value")
            return element_value is not None and element_value != ""
        except NoSuchElementException:
            return False
    return _predicate


# ----------------- æ ¸å¿ƒç™»å…¥é‚è¼¯-----------------
def perform_login(driver):
    """è™•ç† Colorbox å½ˆå‡ºçš„ Iframe ç™»å…¥è¦–çª—ï¼Œä¸¦åŸ·è¡Œç™»å…¥ã€‚"""
    CLASS_NAME = "cboxIframe" 

    #clouadflare token res
    TURNSTILE_LOCATOR = (By.NAME, "cf-turnstile-response")

    try:
        # 1. ç­‰å¾… Iframe å‡ºç¾ä¸¦åˆ‡æ›
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ” æ­£åœ¨ç­‰å¾… Colorbox Iframe å‡ºç¾...")
        WebDriverWait(driver, 20).until(
            EC.frame_to_be_available_and_switch_to_it((By.CLASS_NAME, CLASS_NAME))
        )
        print(f"[{time.strftime('%H:%M:%S')}]   âœ… æˆåŠŸåˆ‡æ›åˆ°ç™»å…¥ Iframeï¼")

        # 2. ç­‰å¾… Turnstile é©—è­‰å®Œæˆ
        print(f"[{time.strftime('%H:%M:%S')}] â³ ç­‰å¾… Cloudflare Turnstile å®Œæˆé©—è­‰...")
        WebDriverWait(driver, 30).until( 
            element_has_non_empty_value(TURNSTILE_LOCATOR)
        )
        recaptcha_code = driver.find_element(*TURNSTILE_LOCATOR).get_attribute("value")
        print(f"[{time.strftime('%H:%M:%S')}]   âœ… Turnstile é©—è­‰æˆåŠŸï¼Token å·²ç²å–: {recaptcha_code[:10]}...")

        # 3. å¡«å¯«å¸³è™Ÿå¯†ç¢¼ä¸¦é»æ“Šç™»å…¥
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ” æ­£åœ¨å®šä½ä¸¦å¡«å¯«ç™»å…¥è³‡è¨Š...")
        acc_field = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, "acc")))
        acc_field.send_keys(YOUR_USERNAME)
        id_field = driver.find_element(By.ID, "id")
        id_field.send_keys(YOUR_ID)
        login_button = driver.find_element(By.ID, "loginBtn")
        
        # 4. é»æ“Šç™»å…¥
        print(f"[{time.strftime('%H:%M:%S')}]   âœ… ç™»å…¥æŒ‰éˆ•é»æ“Šå®Œæˆï¼Œç­‰å¾…å›æ‡‰...")
        login_button.click()
        
        # 5. ç­‰å¾… Iframe æ¶ˆå¤±ä¸¦åˆ‡æ›å›ä¸»æ¡†æ¶
        WebDriverWait(driver, 5).until(EC.invisibility_of_element_located((By.CLASS_NAME, CLASS_NAME)))
        driver.switch_to.default_content()

        time.sleep(2)
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ‰ ç™»å…¥æˆåŠŸï¼")
        return True

    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] âš ï¸ ç™»å…¥æ“ä½œå¤±æ•—ï¼")
        try:
            driver.switch_to.default_content()
            driver.get_screenshot_as_file("login_fail_screenshot.png")
            print(f"[{time.strftime('%H:%M:%S')}]   å·²ä¿å­˜æˆªåœ–ï¼šlogin_fail_screenshot.png")
        except:
            pass
        print(f"[{time.strftime('%H:%M:%S')}] ğŸš¨ ç™»å…¥æ“ä½œå¤±æ•—ï¼ŒéŒ¯èª¤è¨Šæ¯: {e}")
        return False
    finally:
        try:
            driver.switch_to.default_content()
        except:
            pass
            

# ----------------- æ ¸å¿ƒè§£æèˆ‡æœå°‹é‚è¼¯-----------------

def parse_shop_results(driver, keyword) -> list[AuctionItem]:
    """
    å¾æŸ¥è©¢çµæœè¡¨æ ¼ä¸­è§£æç•¶å‰é é¢çš„æ‰€æœ‰éœ²å¤©å•†åº—é“å…·è³‡æ–™ã€‚
    
    æ ¸å¿ƒéæ¿¾é‚è¼¯ï¼šåªä¿ç•™ item_name å’Œå‚³å…¥çš„ keyword å®Œå…¨ç›¸ç¬¦çš„è¨˜éŒ„ã€‚
    """
    items_list = []
    try:
        results_tbody = driver.find_element(By.ID, "_tbody")
        rows = results_tbody.find_elements(By.TAG_NAME, "tr")
        
        if not rows:
            return items_list 
        
        for row in rows:
            try:
                shop_name = row.find_element(By.CLASS_NAME, "shopName").text.strip()
                item_name = row.find_element(By.CLASS_NAME, "itemName").text.strip()
                slot = row.find_element(By.CLASS_NAME, "slot").text.strip()
                price_raw = row.find_element(By.CSS_SELECTOR, ".price > span").text.strip().replace(',', '')
                price = int(price_raw)
                quantity_raw = row.find_element(By.CLASS_NAME, "quantity").text.strip()
                quantity = int(quantity_raw)
                trade_type = row.find_element(By.CSS_SELECTOR, ".buySell > span").text.strip()
                
                # ----------------- âœ… åš´æ ¼éæ¿¾é‚è¼¯ï¼šitem_name == keyword -----------------
                # åªæœ‰ç•¶å•†å“åç¨±èˆ‡æœå°‹é—œéµå­—å®Œå…¨ç›¸ç¬¦æ™‚ï¼Œæ‰å»ºç«‹ä¸¦åŠ å…¥åˆ—è¡¨
                if item_name == keyword:
                    item = AuctionItem(
                        shop_name=shop_name, 
                        item_name=item_name, 
                        slot=slot if slot != '-' else '',
                        price=price, 
                        quantity=quantity, 
                        trade_type=trade_type,
                    )
                    items_list.append(item)
                # ------------------------------------------------------------------------
                
            except Exception:
                # è§£æå–®è¡Œæ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè·³éè©²è¡Œ
                continue
                
        return items_list
        
    except (NoSuchElementException, Exception) as e:
        # æ‰¾ä¸åˆ°è¡¨æ ¼ (ä¾‹å¦‚æŸ¥è©¢çµæœç‚ºç©º) æˆ–å…¶ä»–ç•°å¸¸
        return items_list

def perform_search_and_get_page_count(driver, item_keyword: str) -> tuple[list[AuctionItem], int]:
    """åŸ·è¡Œæœå°‹æ­¥é©Ÿä¸¦è¿”å›ç¬¬ä¸€é è³‡æ–™èˆ‡ç¸½é æ•¸ã€‚"""
    # ... (çœç•¥æœå°‹é‚è¼¯ç´°ç¯€ï¼Œèˆ‡æ‚¨æä¾›çš„ä»£ç¢¼ç›¸åŒ)
    SERVER_NAME = "è¥¿æ ¼å€«"
    SEARCH_BUTTON_ID = "a_searchBtn" 
    SERVER_XPATH = "//ol[@class='select__ol']/li[text()='è¥¿æ ¼å€«']"
    
    try:
        # 1. ç¢ºä¿ä¼ºæœå™¨é¸æ“‡å™¨ç©©å®š
        WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.ID, "div_svr")))
        time.sleep(0.5)
        
        # 2. å˜—è©¦é—œé–‰ SweetAlert2 å½ˆçª—
        SWEETALERT_OK_BUTTON = (By.CLASS_NAME, "swal2-confirm")
        try:
             ok_button = WebDriverWait(driver, 1).until(EC.element_to_be_clickable(SWEETALERT_OK_BUTTON))
             ok_button.click()
             print(f"[{time.strftime('%H:%M:%S')}] Â - âš ï¸ åµæ¸¬åˆ°å½ˆçª—ä¸¦é—œé–‰ã€‚")
             time.sleep(0.5)
        except TimeoutException:
             pass

        # 3. é¸æ“‡ä¼ºæœå™¨
        server_display = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, "div_svr")))
        server_display.click()
        time.sleep(0.5) 
        server_option = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, SERVER_XPATH)))
        server_option.click()
        print(f"[{time.strftime('%H:%M:%S')}] Â - âœ… æˆåŠŸé¸æ“‡ä¼ºæœå™¨ï¼šã€{SERVER_NAME}ã€‘")
        time.sleep(0.5) 
        
        # 4. è¼¸å…¥é“å…·é—œéµå­—
        keyword_input = driver.find_element(By.ID, "txb_KeyWord")
        keyword_input.clear()
        keyword_input.send_keys(item_keyword)
        
        # 5. é»æ“ŠæŸ¥è©¢ä¸¦ç­‰å¾…çµæœ
        search_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, SEARCH_BUTTON_ID)))
        search_button.click()
        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, "_tbody")))
        print(f"[{time.strftime('%H:%M:%S')}] Â - ğŸ” æŸ¥è©¢çµæœè¡¨æ ¼å€å¡Šå·²é¡¯ç¤ºã€‚")

        # 6. è§£æç¬¬ä¸€é è³‡æ–™èˆ‡ç²å–ç¸½é æ•¸
        first_page_data = parse_shop_results(driver, keyword_input)
        pagination_ul = driver.find_element(By.CLASS_NAME, "pagination")
        page_links = pagination_ul.find_elements(By.XPATH, ".//li/a[contains(@onclick, 'goPage')]")
        
        max_page = 0
        for link in page_links:
             try:
                 match = re.search(r'goPage\((\d+)\)', link.get_attribute('onclick'))
                 if match:
                     page_num = int(match.group(1))
                     if page_num > 0:
                         max_page = max(max_page, page_num)
             except:
                 continue
        
        print(f"[{time.strftime('%H:%M:%S')}] Â - â„¹ï¸ åµæ¸¬åˆ°ç¸½é æ•¸: {max_page}")
        return first_page_data, max_page
        
    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] Â - âŒ æŸ¥è©¢æˆ–ç²å–é æ•¸å¤±æ•—: {e}")
        return [], 0


def scrape_multiple_pages(driver, max_page: int, initial_data: list[AuctionItem], item_keyword: str) -> list[AuctionItem]:
    """è™•ç†å¤šé çˆ¬å–é‚è¼¯ (ä¿æŒä¸è®Š)ã€‚"""
    if max_page <= 1:
        return initial_data

    all_data = initial_data
    # ... (çœç•¥ç¿»é çˆ¬èŸ²ç´°ç¯€ï¼Œèˆ‡æ‚¨æä¾›çš„ä»£ç¢¼ç›¸åŒ)
    for page_num in range(2, max_page + 1):
        try:
            print(f"[{time.strftime('%H:%M:%S')}] â¡ï¸ é—œéµå­—ã€{item_keyword}ã€‘æ­£åœ¨çˆ¬å–ç¬¬ {page_num}/{max_page} é ...")
            
            link_locator = (By.XPATH, f"//ul[@class='pagination']//a[contains(@onclick, 'goPage({page_num})')]")
            page_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable(link_locator))
            page_link.click()
            
            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, "_tbody")))
            time.sleep(1)

            page_data = parse_shop_results(driver)
            all_data.extend(page_data)
            
            print(f"[{time.strftime('%H:%M:%S')}] Â - âœ… ç¬¬ {page_num} é è§£ææˆåŠŸï¼Œæ–°å¢ {len(page_data)} ç­†è³‡æ–™ã€‚")

        except Exception as e:
            print(f"[{time.strftime('%H:%M:%S')}] Â - âŒ çˆ¬å–é—œéµå­—ã€{item_keyword}ã€‘ç¬¬ {page_num} é æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ã€‚ä¸­æ–·ç¿»é ã€‚")
            break 
            
    return all_data


# ----------------- æ•¸æ“šåˆ†æèˆ‡å„²å­˜é‚è¼¯ (ä¿æŒä¸è®Š) -----------------

def analyze_and_save_summary(all_data: list[AuctionItem], run_timestamp: str):
    """
    å°æœ¬æ¬¡çˆ¬å–çš„æ‰€æœ‰æ•¸æ“šé€²è¡Œåƒ¹æ ¼åˆ†æï¼Œä¸¦å„²å­˜å½™ç¸½çµæœã€‚
    æ•¸æ“šå‡è¨­å·²åœ¨ parse_shop_results éšæ®µç¶“éåš´æ ¼éæ¿¾ã€‚
    """
    
    file_name_prefix = run_timestamp.replace('/', '_').replace(':', '-')
    # æ›´æ”¹æª”æ¡ˆåç¨±ä»¥åæ˜ æ•¸æ“šçš„ç´”æ·¨æ€§
    FILE_NAME = f"{file_name_prefix}_summary.csv"
    
    print(f"\n[{time.strftime('%H:%M:%S')}] ğŸ“Š æ­£åœ¨å° {len(all_data):,} ç­†è¨˜éŒ„é€²è¡Œæ•¸æ“šåˆ†æ...")

    records = []
    for item in all_data:
        record = item.__dict__().copy()
        record['timestamp'] = run_timestamp
        records.append(record)
    
    df = pd.DataFrame(records)
    
    if df.empty:
        print(f"[{time.strftime('%H:%M:%S')}] Â - âš ï¸ ç¯©é¸å¾Œç„¡å¯åˆ†ææ•¸æ“šã€‚")
        return

    df['total_value'] = df['price'] * df['quantity']
    
    # åˆ†çµ„å½™ç¸½ 'è²©å”®' æ•¸æ“š
    df_sell = df[df['trade_type'] == 'è²©å”®'].groupby('item_name').agg(
        sell_quantity=('quantity', 'sum'),
        sell_min_price=('price', 'min'),
        sell_max_price=('price', 'max'),
        sell_total_value=('total_value', 'sum')
    ).reset_index()
    df_sell['sell_avg_price'] = df_sell.apply(
        lambda row: round(row['sell_total_value'] / row['sell_quantity'], 2) if row['sell_quantity'] > 0 else 0.0, axis=1
    ).round(0)
    df_sell = df_sell.drop(columns=['sell_total_value'])
    
    # åˆ†çµ„å½™ç¸½ 'æ”¶è³¼' æ•¸æ“š
    df_buy = df[df['trade_type'] == 'æ”¶è³¼'].groupby('item_name').agg(
        buy_quantity=('quantity', 'sum'),
        buy_min_price=('price', 'min'),
        buy_max_price=('price', 'max'),
        buy_total_value=('total_value', 'sum')
    ).reset_index()
    df_buy['buy_avg_price'] = df_buy.apply(
        lambda row: round(row['buy_total_value'] / row['buy_quantity'], 2) if row['buy_quantity'] > 0 else 0.0, axis=1
    ).round(0)
    df_buy = df_buy.drop(columns=['buy_total_value'])
    
    # åˆä½µå’Œé‡æ–°å‘½å
    final_summary = pd.merge(df_sell, df_buy, on='item_name', how='outer').fillna(0)
    
    final_summary = final_summary.rename(columns={
        'sell_quantity': 'ç¸½æ•¸é‡(è²©è³£)', 'buy_quantity': 'ç¸½æ•¸é‡(æ”¶è³¼)', 'sell_min_price': 'è²©è³£æœ€ä½åƒ¹', 
        'sell_max_price': 'è²©è³£æœ€é«˜åƒ¹', 'sell_avg_price': 'è²©è³£åŠ æ¬Šå¹³å‡åƒ¹', 'buy_min_price': 'æ”¶è³¼æœ€ä½åƒ¹', 
        'buy_max_price': 'æ”¶è³¼æœ€é«˜åƒ¹', 'buy_avg_price': 'æ”¶è³¼åŠ æ¬Šå¹³å‡åƒ¹'
    })
    
    final_summary = final_summary[[
        'item_name', 'ç¸½æ•¸é‡(è²©è³£)', 'ç¸½æ•¸é‡(æ”¶è³¼)', 'è²©è³£æœ€ä½åƒ¹', 'è²©è³£æœ€é«˜åƒ¹', 
        'è²©è³£åŠ æ¬Šå¹³å‡åƒ¹', 'æ”¶è³¼æœ€ä½åƒ¹', 'æ”¶è³¼æœ€é«˜åƒ¹', 'æ”¶è³¼åŠ æ¬Šå¹³å‡åƒ¹'
    ]]
    
    # åƒ¹æ ¼æ¬„ä½è™•ç†
    price_cols = ['è²©è³£æœ€ä½åƒ¹', 'è²©è³£æœ€é«˜åƒ¹', 'è²©è³£åŠ æ¬Šå¹³å‡åƒ¹', 'æ”¶è³¼æœ€ä½åƒ¹', 'æ”¶è³¼æœ€é«˜åƒ¹', 'æ”¶è³¼åŠ æ¬Šå¹³å‡åƒ¹']
    for col in price_cols:
          final_summary[col] = final_summary[col].apply(lambda x: int(round(x)) if x > 0 else 0)
    
    try:
        final_summary.to_csv(FILE_NAME, index=False, encoding='utf-8') 
        print(f"[{time.strftime('%H:%M:%S')}] Â  - âœ… æˆåŠŸå°‡ {len(final_summary)} ç­†å½™ç¸½è¨˜éŒ„å„²å­˜åˆ° **{FILE_NAME}**ã€‚")
    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] Â  - âŒ å„²å­˜å½™ç¸½æª”æ¡ˆå¤±æ•—: {e}")

    print("\n--- æœ¬æ¬¡å½™ç¸½çµæœ (åƒ…é™ç´”æ·¨é“å…·) ---")
    print(final_summary.to_markdown(index=False, floatfmt=".0f"))
    print("----------------------------------\n")


# ----------------- Git è‡ªå‹•æ¨é€é‚è¼¯ (å·²ä¿®æ”¹ï¼šå¢åŠ  Pull/Rebase) -----------------
def auto_git_push(commit_message):
    """åŸ·è¡Œ git add, commit, pull (rebase), å’Œ pushï¼Œå°‡æ–°çš„ CSV æ•¸æ“šä¸Šå‚³åˆ° GitHubã€‚"""
    try:
        print("\n>>> åŸ·è¡Œ Git è‡ªå‹•æ¨é€ (Add -> Commit -> Pull/Rebase -> Push)...")
        
        # 1. Add å’Œ Commit
        subprocess.run(['git', 'add', '*.csv'], check=True, capture_output=True)
        # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´å¯æäº¤ (é¿å…ç©ºæäº¤å°è‡´å¾ŒçºŒæ­¥é©Ÿå¤±æ•—)
        commit_result = subprocess.run(
            ['git', 'commit', '-m', commit_message], 
            check=False, # å…è¨±éé›¶é€€å‡ºç¢¼ (ç•¶æ²’æœ‰è®Šæ›´æ™‚)
            capture_output=True
        )
        if commit_result.returncode != 0 and b'nothing to commit' in commit_result.stdout:
            print("â„¹ï¸ ç„¡æ–°çš„ CSV è®Šæ›´éœ€è¦æäº¤ã€‚è·³é Pull å’Œ Pushã€‚")
            return
            
        print("âœ… æœ¬åœ°æäº¤å®Œæˆã€‚")
        
        # 2. Pull (Rebase)ï¼šæ‹‰å–é ç«¯è®Šæ›´ï¼Œä¸¦å°‡æœ¬åœ°æäº¤ç–ŠåŠ åœ¨é ç«¯ä¹‹ä¸Šï¼Œä¿æŒç·šæ€§æ­·å²ã€‚
        print("ğŸ” æ­£åœ¨æ‹‰å–é ç«¯æœ€æ–°è®Šæ›´ (git pull --rebase)...")
        # ä½¿ç”¨ --rebase é¿å…åœ¨é ç«¯æœ‰æ–°æäº¤æ™‚ç”¢ç”Ÿåˆä½µæäº¤ (Merge Commit)ï¼Œä¿æŒæ­·å²ä¹¾æ·¨
        subprocess.run(['git', 'pull', '--rebase', 'origin', 'main'], check=True, capture_output=True)
        print("âœ… é ç«¯åŒæ­¥å®Œæˆã€‚")
        
        # 3. Push
        subprocess.run(['git', 'push', 'origin', 'main'], check=True, capture_output=True)
        
        print("ğŸ‰ Git æ“ä½œæˆåŠŸï¼šæœ€æ–° CSV æ•¸æ“šå·²æ¨é€è‡³ GitHubã€‚")

    except subprocess.CalledProcessError as e:
        # ç•¶ pull æˆ– push å¤±æ•—æ™‚ï¼Œé¡¯ç¤ºè©³ç´°éŒ¯èª¤
        print(f"âŒ Git æ“ä½œå¤±æ•—ï¼Œè«‹æª¢æŸ¥æ‚¨çš„ Git ç’°å¢ƒæˆ–èªè­‰ï¼š")
        print(f"STDOUT:\n{e.stdout.decode()}")
        print(f"STDERR:\n{e.stderr.decode()}")
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° Git å‘½ä»¤ã€‚è«‹ç¢ºä¿æ‚¨çš„ç³»çµ±å·²å®‰è£ Gitã€‚")


# ----------------- å–®æ¬¡æ’ç¨‹ä»»å‹™æ ¸å¿ƒé‚è¼¯ (ä¿æŒä¸è®Š) -----------------
def run_scraping_task(driver, SEARCH_ITEMS, run_timestamp_for_file):
    """åŸ·è¡Œæ‰€æœ‰é—œéµå­—çš„çˆ¬èŸ²å’Œæ•¸æ“šè™•ç†ã€‚"""
    
    # ... (çœç•¥ run_scraping_task å‡½æ•¸ç´°ç¯€ï¼Œèˆ‡æ‚¨æä¾›çš„ä»£ç¢¼ç›¸åŒ)
    print("\n" + "="*80)
    print(" " * 28 + "ã€çˆ¬èŸ²ä»»å‹™é–‹å§‹ã€‘")
    print(f" " * 28 + f"ã€æ’ç¨‹æ™‚é–“æˆ³: {run_timestamp_for_file}ã€‘")
    print("="*80)

    all_data_for_summary: list[AuctionItem] = []
    total_records = 0

    try:
        # å˜—è©¦ä¸€å€‹ç°¡å–®æ“ä½œä¾†æª¢æŸ¥ Driver æ˜¯å¦æœ‰æ•ˆ
        driver.find_element(By.ID, "a_searchBtn").click() 
        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, "div_svr")))
        time.sleep(1)

        for item_keyword in SEARCH_ITEMS:
            print("\n" + "#"*60)
            print(f"[{time.strftime('%H:%M:%S')}] - ã€é–‹å§‹è™•ç†é—œéµå­—ï¼š{item_keyword.upper()}ã€‘")
            print("#"*60)
            
            initial_data, max_page = perform_search_and_get_page_count(driver, item_keyword)

            if max_page > 0:
                full_item_data = scrape_multiple_pages(driver, max_page, initial_data, item_keyword)
            else:
                full_item_data = initial_data
            
            all_data_for_summary.extend(full_item_data)
            total_records += len(full_item_data)
            print(f"[{time.strftime('%H:%M:%S')}] - âœ… é—œéµå­—ã€{item_keyword}ã€‘æ•¸æ“šæ”¶é›†å®Œç•¢ï¼Œç¸½å…± {len(full_item_data)} ç­†è³‡æ–™ã€‚")

        # --- æ•¸æ“šåˆ†æã€å„²å­˜å½™ç¸½ CSV èˆ‡ Git æ¨é€ ---
        if total_records > 0:
            analyze_and_save_summary(all_data_for_summary, run_timestamp_for_file)
            
            # *** è‡ªå‹• Git æ¨é€æœ€æ–° CSV ***
            timestamp_for_commit = datetime.now().strftime("%Y-%m-%d %H:%M")
            commit_msg = f"Hourly data update (CSV) via scraper: {timestamp_for_commit}"
            
            auto_git_push(commit_msg)
            # *******************************
            
        else:
            print(f"[{time.strftime('%H:%M:%S')}] âš ï¸ æœ¬æ¬¡æ’ç¨‹æ²’æœ‰çˆ¬å–åˆ°ä»»ä½•è¨˜éŒ„ï¼Œè·³éæ•¸æ“šåˆ†æã€‚")

        print(f"\n[{time.strftime('%H:%M:%S')}] âœ¨ **æœ¬æ¬¡çˆ¬èŸ²ç¸½è¨ˆ {total_records:,} ç­†è¨˜éŒ„ã€‚**")
        return True 

    except WebDriverException as e:
        print(f"[{time.strftime('%H:%M:%S')}] ğŸš¨ çˆ¬èŸ²ä»»å‹™åŸ·è¡ŒæœŸé–“ç™¼ç”Ÿ WebDriver éŒ¯èª¤: {e}")
        return False 

    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] ğŸš¨ çˆ¬èŸ²ä»»å‹™åŸ·è¡ŒæœŸé–“ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
        return True

def wait_until_next_hour(seconds_to_wait_after_full_hour=3, force_run=False):
 
    if force_run:
        print("-" * 50)
        print(f"[{time.strftime('%H:%M:%S')}] âš™ï¸ **é–‹ç™¼æ¨¡å¼ï¼šå¼·åˆ¶ç«‹å³åŸ·è¡Œä»»å‹™ã€‚**")
        print("-" * 50)
        return

    now = datetime.now()
    # è¨ˆç®—ä¸‹ä¸€å€‹å°æ™‚çš„æ™‚é–“ (ä¾‹å¦‚ 13:58:30 -> 14:00:00)
    next_hour = now.replace(minute=0, second=0, microsecond=0)
    next_hour = next_hour.replace(hour=(now.hour + 1) % 24)

    # è¨ˆç®—éœ€è¦ç­‰å¾…çš„ç§’æ•¸ï¼Œå†åŠ ä¸Šé ç•™çš„å»¶é²ç§’æ•¸
    time_to_wait = (next_hour - now).total_seconds() + seconds_to_wait_after_full_hour
    
    # è™•ç†è·¨è¶Šæ•´é»å‰å•Ÿå‹•çš„æƒ…æ³
    if time_to_wait < 0:
         next_hour = next_hour.replace(hour=(next_hour.hour + 1) % 24)
         time_to_wait = (next_hour - now).total_seconds() + seconds_to_wait_after_full_hour
    
    print("-" * 50)
    print(f"[{now.strftime('%H:%M:%S')}] â±ï¸ ä»»å‹™çµæŸï¼Œæ­£åœ¨ç­‰å¾…ä¸‹ä¸€å€‹æ•´é»åŸ·è¡Œã€‚")
    print(f"[{now.strftime('%H:%M:%S')}] Â  Â ä¸‹ä¸€æ¬¡é è¨ˆåŸ·è¡Œæ™‚é–“: **{next_hour.strftime('%H:00:%S')}** (åŒ…å« {seconds_to_wait_after_full_hour} ç§’å»¶é²)")
    print(f"[{now.strftime('%H:%M:%S')}] Â  Â éœ€ç­‰å¾…ç´„ **{int(time_to_wait // 60)} åˆ† {int(time_to_wait % 60)} ç§’**ã€‚")
    print("-" * 50)
    
    time.sleep(time_to_wait)


# ----------------- ä¸»æµç¨‹-----------------

def run_hourly_monitoring_cycle(url: str):
    """
    æŒçºŒç›£è½æ™‚é–“ï¼Œåœ¨æ¯å€‹æ•´é»åˆå§‹åŒ– Driver -> ç™»å…¥ -> çˆ¬èŸ² -> é—œé–‰ Driverã€‚
    """
    SEARCH_ITEMS = ["é‹", "å¤§å˜´é³¥å¡ç‰‡", "ç¥ä¹‹é‡‘å±¬"] 
    
    while True:
        # 1. ç­‰å¾…åˆ°ä¸‹ä¸€å€‹æ•´é»
        wait_until_next_hour(seconds_to_wait_after_full_hour=3, force_run=False) 

        # 2. åˆå§‹åŒ– Driver & ç™»å…¥
        driver = None
        login_success = False
        MAX_RETRIES = 2
        for attempt in range(1, MAX_RETRIES + 1):
            try:
                # ç¢ºä¿åœ¨å˜—è©¦ç™»å…¥å‰å…ˆé—œé–‰å¯èƒ½çš„èˆŠ driver
                if driver:
                    try: driver.quit() 
                    except: pass
                    
                print(f"[{time.strftime('%H:%M:%S')}] ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æ–°çš„ç€è¦½å™¨ Driver...")
                options = uc.ChromeOptions()
                driver = uc.Chrome(options=options)
                driver.get(url)
                time.sleep(3) 

                # é»æ“Šç™»å…¥é€£çµä¸¦åŸ·è¡Œç™»å…¥
                LOGIN_LINK_ID = "a_searchBtn"
                login_link = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.ID, LOGIN_LINK_ID)))
                login_link.click()
                login_success = perform_login(driver)
                
                if login_success:
                    break
                    
                if attempt < MAX_RETRIES:
                    print(f"[{time.strftime('%H:%M:%S')}] ğŸ˜¥ ç¬¬ {attempt} æ¬¡åˆå§‹åŒ–/ç™»å…¥å¤±æ•—ï¼Œæ­£åœ¨é‡è©¦...")
                
            except Exception as e:
                print(f"[{time.strftime('%H:%M:%S')}] âŒ ç€è¦½å™¨æˆ–ç™»å…¥åˆå§‹åŒ–å¤±æ•—: {e}")
                if attempt < MAX_RETRIES:
                     print(f"[{time.strftime('%H:%M:%S')}] ğŸ˜¥ ç¬¬ {attempt} æ¬¡åˆå§‹åŒ–/ç™»å…¥å¤±æ•—ï¼Œæ­£åœ¨é‡è©¦...")


        if login_success and driver:
            # 3. åŸ·è¡Œä»»å‹™
            now = datetime.now()
            run_timestamp_for_file = now.strftime('%Y/%#m/%#d/%#H')
            run_scraping_task(driver, SEARCH_ITEMS, run_timestamp_for_file) 
        else:
            print(f"[{time.strftime('%H:%M:%S')}] ğŸ˜¥ ç™»å…¥å¤±æ•—ï¼Œè·³éæœ¬æ¬¡çˆ¬èŸ²ä»»å‹™ã€‚")

        # 4. é—œé–‰ Driver
        if driver:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ§¹ ä»»å‹™çµæŸï¼Œæ­£åœ¨é—œé–‰ç€è¦½å™¨ Driver...")
            try:
                driver.quit() 
            except Exception:
                pass
        
        # è¿´åœˆè¿”å›æ­¥é©Ÿ 1: å†æ¬¡ç­‰å¾…ä¸‹ä¸€å€‹æ•´é»


# --- åŸ·è¡Œç¨‹å¼ç¢¼ (å·²ä¿®æ”¹) ---
if __name__ == '__main__':
    target_url = "https://event.gnjoy.com.tw/RoZ/RoZ_ShopSearch" 
    print("==============================================")
    print("       ğŸ‰ çˆ¬èŸ²ç›£è½ç¨‹å¼å·²å•Ÿå‹• ğŸ‰")
    print(" ç¨‹å¼å°‡æŒçºŒé‹è¡Œï¼Œä¸¦åœ¨æ¯å€‹æ•´é»è‡ªå‹•åŸ·è¡Œä»»å‹™ã€‚")
    print("==============================================")
    run_hourly_monitoring_cycle(target_url)