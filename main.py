# æª”æ¡ˆ: main_scraper.py (å·²å„ªåŒ–ç‚º GitHub Actions ç’°å¢ƒ)

from datetime import datetime
import os
import undetected_chromedriver as uc
import time
import subprocess 
import re
import pandas as pd
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException


# ----------------- ç’°å¢ƒè®Šæ•¸ (ç›´æ¥å¾ Actions Secrets è®€å–) -----------------

# é€™äº›è®Šæ•¸æœƒç›´æ¥å¾ GitHub Actions çš„ 'env:' å€å¡Šæˆ–ç³»çµ±ç’°å¢ƒè®Šæ•¸ä¸­è®€å–
# ç¢ºä¿æ‚¨å·²åœ¨ Actions YAML ä¸­è¨­å®š AUCTION_USERNAME å’Œ AUCTION_ID
YOUR_USERNAME = os.getenv("AUCTION_USERNAME") 
YOUR_ID = os.getenv("AUCTION_ID")

# æª¢æŸ¥è®Šæ•¸æ˜¯å¦ç‚ºç©ºï¼Œåœ¨ Actions åŸ·è¡Œæ™‚é€™æ˜¯å¿…è¦çš„å®‰å…¨æª¢æŸ¥
if not YOUR_USERNAME or not YOUR_ID:
    print("ğŸš¨ è‡´å‘½éŒ¯èª¤ï¼šç’°å¢ƒè®Šæ•¸ AUCTION_USERNAME æˆ– AUCTION_ID æœªè¨­å®šã€‚è«‹æª¢æŸ¥ GitHub Secretsã€‚")
    # åœ¨é Actions ç’°å¢ƒä¸‹ï¼Œå¯èƒ½éœ€è¦åŠ è¼‰ .env ä¾†æ¸¬è©¦ï¼Œä½†é€™è£¡ä¿æŒä¹¾æ·¨ç‰ˆæœ¬
    # exit(1) # åœ¨å¯¦éš›éƒ¨ç½²æ™‚å»ºè­°å•Ÿç”¨ï¼Œä½†åœ¨æ¸¬è©¦éšæ®µå…ˆè¨»è§£

# ----------------- Cloudflare Checkbox è™•ç†é‚è¼¯ -----------------

def handle_cloudflare_challenge(driver):
    """
    åµæ¸¬ä¸¦å˜—è©¦é»æ“Š Cloudflare çš„ "é©—è­‰æ‚¨æ˜¯äººé¡" Checkboxã€‚
    """
    CHECKBOX_LOCATOR = (By.CSS_SELECTOR, "label.cb-lb input[type='checkbox']")
    CHECKBOX_LABEL_LOCATOR = (By.CLASS_NAME, "cb-lb") # æœ‰æ™‚é»æ“Š Label æ›´æœ‰æ•ˆ

    print(f"[{time.strftime('%H:%M:%S')}] ğŸ” æ­£åœ¨æª¢æŸ¥æ˜¯å¦æœ‰ Cloudflare Checkbox æŒ‘æˆ°...")
    
    try:
        # ç­‰å¾… Checkbox çš„ Label å…ƒç´ å‡ºç¾
        WebDriverWait(driver, 5).until(
            EC.presence_of_element_located(CHECKBOX_LABEL_LOCATOR)
        )
        
        # æ‰¾åˆ° Checkbox å…ƒç´ 
        checkbox = driver.find_element(*CHECKBOX_LOCATOR)
        
        # é»æ“Šå®ƒ
        if checkbox.is_displayed() and checkbox.is_enabled():
            print(f"[{time.strftime('%H:%M:%S')}] âš ï¸ åµæ¸¬åˆ° Checkboxï¼Œæ­£åœ¨å˜—è©¦é»æ“Š...")
            checkbox.click()
            time.sleep(5) 
            print(f"[{time.strftime('%H:%M:%S')}] âœ… Checkbox é»æ“Šå®Œæˆï¼Œç­‰å¾…é é¢ç¹¼çºŒè¼‰å…¥...")
            return True
            
    except TimeoutException:
        print(f"[{time.strftime('%H:%M:%S')}] â„¹ï¸ æ²’æœ‰åµæ¸¬åˆ° Cloudflare Checkbox æŒ‘æˆ° (Timeout)ã€‚ç¹¼çºŒåŸ·è¡Œã€‚")
        return False
    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] âŒ é»æ“Š Checkbox æŒ‘æˆ°å¤±æ•—: {e}")
        return False


# ----------------- æ ¸å¿ƒç­‰å¾…é‚è¼¯ -----------------
def element_has_non_empty_value(locator):
    """è‡ªå®šç¾© EC æ¢ä»¶ï¼šç­‰å¾…å…ƒç´ çš„ 'value' å±¬æ€§è®Šç‚ºéç©º (ç”¨æ–¼ Turnstile Token)ã€‚"""
    def _predicate(driver):
        try:
            element = driver.find_element(*locator)
            element_value = element.get_attribute("value")
            return element_value is not None and element_value != ""
        except NoSuchElementException:
            return False
    return _predicate


# ----------------- æ ¸å¿ƒç™»å…¥é‚è¼¯-----------------
def perform_login(driver):
    """è™•ç† Colorbox å½ˆå‡ºçš„ Iframe ç™»å…¥è¦–çª—ï¼Œä¸¦åŸ·è¡Œç™»å…¥ã€‚"""
    CLASS_NAME = "cboxIframe" 
    TURNSTILE_LOCATOR = (By.NAME, "cf-turnstile-response")

    # å¦‚æœç’°å¢ƒè®Šæ•¸ç‚ºç©ºï¼Œç›´æ¥è·³éç™»å…¥
    if not YOUR_USERNAME or not YOUR_ID:
        print(f"[{time.strftime('%H:%M:%S')}] âŒ ç’°å¢ƒè®Šæ•¸ç¼ºå¤±ï¼Œç„¡æ³•åŸ·è¡Œç™»å…¥ã€‚")
        return False

    try:
        # 1. ç­‰å¾… Iframe å‡ºç¾ä¸¦åˆ‡æ›
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ” æ­£åœ¨ç­‰å¾… Colorbox Iframe å‡ºç¾...")
        WebDriverWait(driver, 20).until(
            EC.frame_to_be_available_and_switch_to_it((By.CLASS_NAME, CLASS_NAME))
        )
        print(f"[{time.strftime('%H:%M:%S')}] âœ… æˆåŠŸåˆ‡æ›åˆ°ç™»å…¥ Iframeï¼")

        # 2. ç­‰å¾… Turnstile é©—è­‰å®Œæˆ
        print(f"[{time.strftime('%H:%M:%S')}] â³ ç­‰å¾… Cloudflare Turnstile å®Œæˆé©—è­‰...")
        WebDriverWait(driver, 30).until( 
            element_has_non_empty_value(TURNSTILE_LOCATOR)
        )
        recaptcha_code = driver.find_element(*TURNSTILE_LOCATOR).get_attribute("value")
        print(f"[{time.strftime('%H:%M:%S')}] âœ… Turnstile é©—è­‰æˆåŠŸï¼Token å·²ç²å–: {recaptcha_code[:10]}...")

        # 3. å¡«å¯«å¸³è™Ÿå¯†ç¢¼ä¸¦é»æ“Šç™»å…¥
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ” æ­£åœ¨å®šä½ä¸¦å¡«å¯«ç™»å…¥è³‡è¨Š...")
        acc_field = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, "acc")))
        acc_field.send_keys(YOUR_USERNAME)
        id_field = driver.find_element(By.ID, "id")
        id_field.send_keys(YOUR_ID)
        login_button = driver.find_element(By.ID, "loginBtn")
        
        # 4. é»æ“Šç™»å…¥
        print(f"[{time.strftime('%H:%M:%S')}] âœ… ç™»å…¥æŒ‰éˆ•é»æ“Šå®Œæˆï¼Œç­‰å¾…å›æ‡‰...")
        login_button.click()
        
        # 5. ç­‰å¾… Iframe æ¶ˆå¤±ä¸¦åˆ‡æ›å›ä¸»æ¡†æ¶
        WebDriverWait(driver, 5).until(EC.invisibility_of_element_located((By.CLASS_NAME, CLASS_NAME)))
        driver.switch_to.default_content()

        time.sleep(2)
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ‰ ç™»å…¥æˆåŠŸï¼")
        return True

    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] âš ï¸ ç™»å…¥æ“ä½œå¤±æ•—ï¼")
        try:
            driver.switch_to.default_content()
            driver.get_screenshot_as_file("login_fail_screenshot.png")
            print(f"[{time.strftime('%H:%M:%S')}] å·²ä¿å­˜æˆªåœ–ï¼šlogin_fail_screenshot.png")
        except:
            pass
        print(f"[{time.strftime('%H:%M:%S')}] ğŸš¨ ç™»å…¥æ“ä½œå¤±æ•—ï¼ŒéŒ¯èª¤è¨Šæ¯: {e}")
        return False
    finally:
        try:
            driver.switch_to.default_content()
        except:
            pass
            

# ----------------- æ ¸å¿ƒè§£æèˆ‡æœå°‹é‚è¼¯-----------------

def parse_shop_results(driver, keyword) -> list:
    """å¾æŸ¥è©¢çµæœè¡¨æ ¼ä¸­è§£æç•¶å‰é é¢çš„è³‡æ–™ï¼Œä¸¦é€²è¡Œåš´æ ¼éæ¿¾ (item_name == keyword)ã€‚"""
    items_list = []
    try:
        results_tbody = driver.find_element(By.ID, "_tbody")
        rows = results_tbody.find_elements(By.TAG_NAME, "tr")
        
        if not rows:
            return items_list 
        
        for row in rows:
            try:
                shop_name = row.find_element(By.CLASS_NAME, "shopName").text.strip()
                item_name = row.find_element(By.CLASS_NAME, "itemName").text.strip()
                slot = row.find_element(By.CLASS_NAME, "slot").text.strip()
                price_raw = row.find_element(By.CSS_SELECTOR, ".price > span").text.strip().replace(',', '')
                price = int(price_raw)
                quantity_raw = row.find_element(By.CLASS_NAME, "quantity").text.strip()
                quantity = int(quantity_raw)
                trade_type = row.find_element(By.CSS_SELECTOR, ".buySell > span").text.strip()
                
                # åš´æ ¼éæ¿¾é‚è¼¯ï¼šitem_name å¿…é ˆèˆ‡æœå°‹é—œéµå­—å®Œå…¨ç›¸ç¬¦
                if item_name == keyword:
                    item_data = {
                        'shop_name': shop_name, 
                        'item_name': item_name, 
                        'slot': slot if slot != '-' else '',
                        'price': price, 
                        'quantity': quantity, 
                        'trade_type': trade_type,
                    }
                    items_list.append(item_data)
                
            except Exception:
                # è§£æå–®è¡Œæ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè·³éè©²è¡Œ
                continue
                
        return items_list
        
    except (NoSuchElementException, Exception):
        # æ‰¾ä¸åˆ°è¡¨æ ¼æˆ–å…¶å®ƒç•°å¸¸ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return items_list

def perform_search_and_get_page_count(driver, item_keyword: str) -> tuple[list, int]:
    """åŸ·è¡Œæœå°‹æ­¥é©Ÿä¸¦è¿”å›ç¬¬ä¸€é è³‡æ–™èˆ‡ç¸½é æ•¸ã€‚"""
    SERVER_NAME = "è¥¿æ ¼å€«"
    SEARCH_BUTTON_ID = "a_searchBtn" 
    SERVER_XPATH = "//ol[@class='select__ol']/li[text()='è¥¿æ ¼å€«']"
    
    try:
        # 1. ç¢ºä¿ä¼ºæœå™¨é¸æ“‡å™¨ç©©å®š
        WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.ID, "div_svr")))
        time.sleep(0.5)
        
        # 2. å˜—è©¦é—œé–‰ SweetAlert2 å½ˆçª—
        SWEETALERT_OK_BUTTON = (By.CLASS_NAME, "swal2-confirm")
        try:
            ok_button = WebDriverWait(driver, 1).until(EC.element_to_be_clickable(SWEETALERT_OK_BUTTON))
            ok_button.click()
            print(f"[{time.strftime('%H:%M:%S')}] - âš ï¸ åµæ¸¬åˆ°å½ˆçª—ä¸¦é—œé–‰ã€‚")
            time.sleep(0.5)
        except TimeoutException:
            pass

        # 3. é¸æ“‡ä¼ºæœå™¨
        server_display = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, "div_svr")))
        server_display.click()
        time.sleep(0.5) 
        server_option = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, SERVER_XPATH)))
        server_option.click()
        print(f"[{time.strftime('%H:%M:%S')}] - âœ… æˆåŠŸé¸æ“‡ä¼ºæœå™¨ï¼šã€{SERVER_NAME}ã€‘")
        time.sleep(0.5) 
        
        # 4. è¼¸å…¥é“å…·é—œéµå­—
        keyword_input = driver.find_element(By.ID, "txb_KeyWord")
        keyword_input.clear()
        keyword_input.send_keys(item_keyword)
        
        # 5. é»æ“ŠæŸ¥è©¢ä¸¦ç­‰å¾…çµæœ
        search_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, SEARCH_BUTTON_ID)))
        search_button.click()
        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, "_tbody")))
        print(f"[{time.strftime('%H:%M:%S')}] - ğŸ” æŸ¥è©¢çµæœè¡¨æ ¼å€å¡Šå·²é¡¯ç¤ºã€‚")

        # 6. è§£æç¬¬ä¸€é è³‡æ–™èˆ‡ç²å–ç¸½é æ•¸
        first_page_data = parse_shop_results(driver, item_keyword)
        pagination_ul = driver.find_element(By.CLASS_NAME, "pagination")
        page_links = pagination_ul.find_elements(By.XPATH, ".//li/a[contains(@onclick, 'goPage')]")
        
        max_page = 0
        for link in page_links:
            try:
                match = re.search(r'goPage\((\d+)\)', link.get_attribute('onclick'))
                if match:
                    page_num = int(match.group(1))
                    if page_num > 0:
                        max_page = max(max_page, page_num)
            except:
                continue
        
        print(f"[{time.strftime('%H:%M:%S')}] - â„¹ï¸ åµæ¸¬åˆ°ç¸½é æ•¸: {max_page}")
        return first_page_data, max_page
        
    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] - âŒ æŸ¥è©¢æˆ–ç²å–é æ•¸å¤±æ•—: {e}")
        return [], 0


def scrape_multiple_pages(driver, max_page: int, initial_data: list, item_keyword: str) -> list:
    """è™•ç†å¤šé çˆ¬å–é‚è¼¯"""
    if max_page <= 1:
        return initial_data

    all_data = initial_data
    for page_num in range(2, max_page + 1):
        try:
            print(f"[{time.strftime('%H:%M:%S')}] â¡ï¸ é—œéµå­—ã€{item_keyword}ã€‘æ­£åœ¨çˆ¬å–ç¬¬ {page_num}/{max_page} é ...")
            
            link_locator = (By.XPATH, f"//ul[@class='pagination']//a[contains(@onclick, 'goPage({page_num})')]")
            page_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable(link_locator))
            page_link.click()
            
            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, "_tbody")))
            time.sleep(1)

            page_data = parse_shop_results(driver, item_keyword)
            all_data.extend(page_data)
            
            print(f"[{time.strftime('%H:%M:%S')}] - âœ… ç¬¬ {page_num} é è§£ææˆåŠŸï¼Œæ–°å¢ {len(page_data)} ç­†è³‡æ–™ã€‚")

        except Exception as e:
            print(f"[{time.strftime('%H:%M:%S')}] - âŒ çˆ¬å–é—œéµå­—ã€{item_keyword}ã€‘ç¬¬ {page_num} é æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ã€‚ä¸­æ–·ç¿»é ã€‚")
            break 
            
    return all_data


# ----------------- æ•¸æ“šåˆ†æèˆ‡å„²å­˜é‚è¼¯-----------------

def analyze_and_save_summary(all_data: list, run_timestamp: str):
    """å°æœ¬æ¬¡çˆ¬å–çš„æ‰€æœ‰æ•¸æ“šé€²è¡Œåƒ¹æ ¼åˆ†æï¼Œä¸¦å„²å­˜å½™ç¸½çµæœã€‚"""
    
    file_name_prefix = run_timestamp.replace('/', '_').replace(':', '-')
    FILE_NAME = f"{file_name_prefix}_summary.csv"
    
    print(f"\n[{time.strftime('%H:%M:%S')}] ğŸ“Š æ­£åœ¨å° {len(all_data):,} ç­†è¨˜éŒ„é€²è¡Œæ•¸æ“šåˆ†æ...")

    records = all_data
    for record in records:
          record['timestamp'] = run_timestamp

    df = pd.DataFrame(records)
    
    if df.empty:
        print(f"[{time.strftime('%H:%M:%S')}] - âš ï¸ ç¯©é¸å¾Œç„¡å¯åˆ†ææ•¸æ“šã€‚")
        return

    df['total_value'] = df['price'] * df['quantity']
    
    # åˆ†çµ„å½™ç¸½ 'è²©å”®' æ•¸æ“š
    df_sell = df[df['trade_type'] == 'è²©å”®'].groupby('item_name').agg(
        sell_quantity=('quantity', 'sum'),
        sell_min_price=('price', 'min'),
        sell_max_price=('price', 'max'),
        sell_total_value=('total_value', 'sum')
    ).reset_index()
    df_sell['sell_avg_price'] = df_sell.apply(
        lambda row: round(row['sell_total_value'] / row['sell_quantity'], 2) if row['sell_quantity'] > 0 else 0.0, axis=1
    ).round(0)
    df_sell = df_sell.drop(columns=['sell_total_value'])
    
    # åˆ†çµ„å½™ç¸½ 'æ”¶è³¼' æ•¸æ“š
    df_buy = df[df['trade_type'] == 'æ”¶è³¼'].groupby('item_name').agg(
        buy_quantity=('quantity', 'sum'),
        buy_min_price=('price', 'min'),
        buy_max_price=('price', 'max'),
        buy_total_value=('total_value', 'sum')
    ).reset_index()
    df_buy['buy_avg_price'] = df_buy.apply(
        lambda row: round(row['buy_total_value'] / row['buy_quantity'], 2) if row['buy_quantity'] > 0 else 0.0, axis=1
    ).round(0)
    df_buy = df_buy.drop(columns=['buy_total_value'])
    
    # åˆä½µå’Œé‡æ–°å‘½å
    final_summary = pd.merge(df_sell, df_buy, on='item_name', how='outer').fillna(0)
    
    final_summary = final_summary.rename(columns={
        'sell_quantity': 'ç¸½æ•¸é‡(è²©è³£)', 'buy_quantity': 'ç¸½æ•¸é‡(æ”¶è³¼)', 'sell_min_price': 'è²©è³£æœ€ä½åƒ¹', 
        'sell_max_price': 'è²©è³£æœ€é«˜åƒ¹', 'sell_avg_price': 'è²©è³£åŠ æ¬Šå¹³å‡åƒ¹', 'buy_min_price': 'æ”¶è³¼æœ€ä½åƒ¹', 
        'buy_max_price': 'æ”¶è³¼æœ€é«˜åƒ¹', 'buy_avg_price': 'æ”¶è³¼åŠ æ¬Šå¹³å‡åƒ¹'
    })
    
    final_summary = final_summary[[
        'item_name', 'ç¸½æ•¸é‡(è²©è³£)', 'ç¸½æ•¸é‡(æ”¶è³¼)', 'è²©è³£æœ€ä½åƒ¹', 'è²©è³£æœ€é«˜åƒ¹', 
        'è²©è³£åŠ æ¬Šå¹³å‡åƒ¹', 'æ”¶è³¼æœ€ä½åƒ¹', 'æ”¶è³¼æœ€é«˜åƒ¹', 'æ”¶è³¼åŠ æ¬Šå¹³å‡åƒ¹'
    ]]
    
    # åƒ¹æ ¼æ¬„ä½è™•ç†
    price_cols = ['è²©è³£æœ€ä½åƒ¹', 'è²©è³£æœ€é«˜åƒ¹', 'è²©è³£åŠ æ¬Šå¹³å‡åƒ¹', 'æ”¶è³¼æœ€ä½åƒ¹', 'æ”¶è³¼æœ€é«˜åƒ¹', 'æ”¶è³¼åŠ æ¬Šå¹³å‡åƒ¹']
    for col in price_cols:
          final_summary[col] = final_summary[col].apply(lambda x: int(round(x)) if x > 0 else 0)
    
    try:
        final_summary.to_csv(FILE_NAME, index=False, encoding='utf-8') 
        print(f"[{time.strftime('%H:%M:%S')}] - âœ… æˆåŠŸå°‡ {len(final_summary)} ç­†å½™ç¸½è¨˜éŒ„å„²å­˜åˆ° **{FILE_NAME}**ã€‚")
    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] - âŒ å„²å­˜å½™ç¸½æª”æ¡ˆå¤±æ•—: {e}")

    print("\n--- æœ¬æ¬¡å½™ç¸½çµæœ (åƒ…é™ç´”æ·¨é“å…·) ---")
    print(final_summary.to_markdown(index=False, floatfmt=".0f"))
    print("----------------------------------\n")

# ----------------- Git è‡ªå‹•æ¨é€é‚è¼¯ -----------------
def auto_git_push(commit_message):
    """åŸ·è¡Œ git add, commit, pull (rebase), å’Œ pushï¼Œå°‡æ–°çš„ CSV æ•¸æ“šä¸Šå‚³åˆ° GitHubã€‚"""
    
    stash_popped = False 
    
    try:
        print("\n>>> åŸ·è¡Œ Git è‡ªå‹•æ¨é€ (Stash -> Add CSV -> Commit -> Pull/Rebase -> Push -> Pop)...")
        
        # 0. æª¢æŸ¥ä¸¦æš«å­˜æ‰€æœ‰æœªæäº¤/æœªè¿½è¹¤çš„è®Šæ›´ (åŒ…å«æ–°çš„ CSV æ–‡ä»¶)
        stash_result = subprocess.run(
            ['git', 'stash', 'push', '--include-untracked', '-m', 'SCRAPER_TEMP_STASH'],
            check=False,
            capture_output=True
        )
        # æª¢æŸ¥ stdout ä¾†åˆ¤æ–·æ˜¯å¦çœŸçš„æœ‰æ±è¥¿è¢« Stash
        if b'No local changes to save' not in stash_result.stdout:
            print("âœ… åµæ¸¬åˆ°ä¸¦æˆåŠŸæš«å­˜ (Stash) å·¥ä½œç›®éŒ„è®Šæ›´ (åŒ…æ‹¬æ–° CSV)ã€‚")
            stash_popped = True
        else:
            print("â„¹ï¸ å·¥ä½œç›®éŒ„ä¹¾æ·¨ã€‚ç„¡éœ€æš«å­˜ã€‚")
        
        # 1. æ¢å¾©æš«å­˜çš„è®Šæ›´ã€‚ç›®çš„ï¼šå°‡æ–°ç”Ÿæˆçš„ CSV æ–‡ä»¶æ‹‰å‡ºä¾†ï¼Œä»¥ä¾¿è¢« git add å’Œ commit æ•ç²ã€‚
        if stash_popped:
            subprocess.run(['git', 'stash', 'apply', '--index'], check=True, capture_output=True)
            print("âœ… å·²æ¢å¾©æš«å­˜çš„è®Šæ›´åˆ°å·¥ä½œå€ã€‚")

        # 2. Add æ‰€æœ‰ CSV (é€™æ˜¯æ‚¨æ–°ç”Ÿæˆçš„æª”æ¡ˆ)
        subprocess.run(['git', 'add', '*.csv'], check=True, capture_output=True)
        
        # 3. Commit (åªæœ‰åœ¨æœ‰è®Šæ›´æ™‚æ‰åŸ·è¡Œ)
        commit_result = subprocess.run(
            ['git', 'commit', '-m', commit_message], 
            check=False, 
            capture_output=True
        )
        
        if commit_result.returncode != 0 and b'nothing to commit' in commit_result.stdout:
            print("â„¹ï¸ ç„¡æ–°çš„ CSV è®Šæ›´éœ€è¦æäº¤ã€‚è·³é Pull å’Œ Pushã€‚")
            # å¦‚æœæ²’æœ‰æäº¤ï¼Œä½†æœ‰ Stashï¼Œæˆ‘å€‘éœ€è¦æ¸…ç†ä¸¦æ¢å¾©
            if stash_popped:
                subprocess.run(['git', 'stash', 'pop', '--index'], check=True, capture_output=True)
                print("âœ… å·²æ¸…ç†æš«å­˜çš„è®Šæ›´ã€‚")
            return
            
        print("âœ… æœ¬åœ°æäº¤å®Œæˆã€‚")
        
        # 4. Pull (Rebase)
        print("ğŸ” æ­£åœ¨æ‹‰å–é ç«¯æœ€æ–°è®Šæ›´ (git pull --rebase)...")
        # å‡è¨­æ‚¨çš„ Actions ä½¿ç”¨çš„æ˜¯ GITHUB_TOKENï¼Œé è¨­æ‹‰å–/æ¨é€ main
        subprocess.run(['git', 'pull', '--rebase', 'origin', 'main'], check=True, capture_output=True)
        print("âœ… é ç«¯åŒæ­¥å®Œæˆã€‚")
        
        # 5. Push
        subprocess.run(['git', 'push', 'origin', 'main'], check=True, capture_output=True)
        print("ğŸ‰ Git æ“ä½œæˆåŠŸï¼šæœ€æ–° CSV æ•¸æ“šå·²æ¨é€è‡³ GitHubã€‚")
        
        # 6. æ¸…ç†ä¸¦æ¢å¾©æš«å­˜çš„è®Šæ›´ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if stash_popped:
            subprocess.run(['git', 'stash', 'drop'], check=True, capture_output=True)
            print("âœ… å·²æ¸…ç†æš«å­˜çš„è®Šæ›´ã€‚")


    except subprocess.CalledProcessError as e:
        # åœ¨å¤±æ•—æ™‚ï¼Œæª¢æŸ¥ä¸¦æ¢å¾©åŸå§‹çš„ Stash è®Šæ›´
        if stash_popped:
            try:
                subprocess.run(['git', 'stash', 'pop', '--index'], check=False, capture_output=True)
                print("âš ï¸ Git æ“ä½œå¤±æ•—ï¼Œä½†å·²å˜—è©¦æ¢å¾©æš«å­˜çš„è®Šæ›´ã€‚")
            except:
                pass
                
        print(f"âŒ Git æ“ä½œå¤±æ•—ï¼Œè«‹æª¢æŸ¥æ‚¨çš„ Git ç’°å¢ƒæˆ–èªè­‰ï¼š")
        # æ‰“å°éŒ¯èª¤è¼¸å‡ºï¼Œæ–¹ä¾¿èª¿è©¦
        # print(f"STDOUT:\n{e.stdout.decode()}")
        # print(f"STDERR:\n{e.stderr.decode()}")
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° Git å‘½ä»¤ã€‚è«‹ç¢ºä¿æ‚¨çš„ç³»çµ±å·²å®‰è£ Gitã€‚")

# ----------------- å–®æ¬¡æ’ç¨‹ä»»å‹™æ ¸å¿ƒé‚è¼¯ -----------------
def run_scraping_task(driver, SEARCH_ITEMS, run_timestamp_for_file):
    """åŸ·è¡Œæ‰€æœ‰é—œéµå­—çš„çˆ¬èŸ²å’Œæ•¸æ“šè™•ç†ã€‚"""
    
    print("\n" + "="*80)
    print(" " * 28 + "ã€çˆ¬èŸ²ä»»å‹™é–‹å§‹ã€‘")
    print(f" " * 28 + f"ã€æ’ç¨‹æ™‚é–“æˆ³: {run_timestamp_for_file}ã€‘")
    print("="*80)

    all_data_for_summary: list = []
    total_records = 0

    try:
        # å˜—è©¦ä¸€å€‹ç°¡å–®æ“ä½œä¾†æª¢æŸ¥ Driver æ˜¯å¦æœ‰æ•ˆ
        driver.find_element(By.ID, "a_searchBtn").click() 
        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, "div_svr")))
        time.sleep(1)

        for item_keyword in SEARCH_ITEMS:
            print("\n" + "#"*60)
            print(f"[{time.strftime('%H:%M:%S')}] - ã€é–‹å§‹è™•ç†é—œéµå­—ï¼š{item_keyword.upper()}ã€‘")
            print("#"*60)
            
            initial_data, max_page = perform_search_and_get_page_count(driver, item_keyword)

            if max_page > 0:
                full_item_data = scrape_multiple_pages(driver, max_page, initial_data, item_keyword)
            else:
                full_item_data = initial_data
            
            all_data_for_summary.extend(full_item_data)
            total_records += len(full_item_data)
            print(f"[{time.strftime('%H:%M:%S')}] - âœ… é—œéµå­—ã€{item_keyword}ã€‘æ•¸æ“šæ”¶é›†å®Œç•¢ï¼Œç¸½å…± {len(full_item_data)} ç­†è³‡æ–™ã€‚")

        # --- æ•¸æ“šåˆ†æã€å„²å­˜å½™ç¸½ CSV èˆ‡ Git æ¨é€ ---
        if total_records > 0:
            analyze_and_save_summary(all_data_for_summary, run_timestamp_for_file)
            
            # *** è‡ªå‹• Git æ¨é€æœ€æ–° CSV ***
            timestamp_for_commit = datetime.now().strftime("%Y-%m-%d %H:%M")
            commit_msg = f"Hourly data update (CSV) via scraper: {timestamp_for_commit}"
            
            auto_git_push(commit_msg)
            # *******************************
            
        else:
            print(f"[{time.strftime('%H:%M:%S')}] âš ï¸ æœ¬æ¬¡æ’ç¨‹æ²’æœ‰çˆ¬å–åˆ°ä»»ä½•è¨˜éŒ„ï¼Œè·³éæ•¸æ“šåˆ†æã€‚")

        print(f"\n[{time.strftime('%H:%M:%S')}] âœ¨ **æœ¬æ¬¡çˆ¬èŸ²ç¸½è¨ˆ {total_records:,} ç­†è¨˜éŒ„ã€‚**")
        return True 

    except WebDriverException as e:
        print(f"[{time.strftime('%H:%M:%S')}] ğŸš¨ çˆ¬èŸ²ä»»å‹™åŸ·è¡ŒæœŸé–“ç™¼ç”Ÿ WebDriver éŒ¯èª¤: {e}")
        return False 

    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] ğŸš¨ çˆ¬èŸ²ä»»å‹™åŸ·è¡ŒæœŸé–“ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
        return True


# ----------------- ä¸»æµç¨‹-----------------

def run_hourly_monitoring_cycle(url: str):
    """
    åŸ·è¡Œä¸€æ¬¡åˆå§‹åŒ– Driver -> ç™»å…¥ -> çˆ¬èŸ² -> é—œé–‰ Driverã€‚
    """
    SEARCH_ITEMS = ["é‹", "å¤§å˜´é³¥å¡ç‰‡", "ç¥ä¹‹é‡‘å±¬"] 
    
    # ... (åˆå§‹åŒ–å’Œé‡è©¦é‚è¼¯) ...
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            # ... (æ¸…ç†èˆŠ Driver é‚è¼¯) ...
            
            print(f"[{time.strftime('%H:%M:%S')}] ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æ–°çš„ç€è¦½å™¨ Driver...")
            
            # ã€é‡è¦ä¿®æ­£ã€‘ï¼šæ–°å¢ç„¡é ­æ¨¡å¼å’Œå¿…è¦çš„åƒæ•¸
            options = uc.ChromeOptions()
            options.add_argument('--no-sandbox')         # æ¶ˆé™¤æ²™ç®±æ¨¡å¼çš„æ¬Šé™å•é¡Œ (Linux å¿…éœ€)
            options.add_argument('--headless')           # å¼·åˆ¶ç„¡é ­æ¨¡å¼ (é¿å…åœ–å½¢ç•Œé¢ä¾è³´)
            options.add_argument('--disable-dev-shm-usage') # è§£æ±º Linux å…§å­˜å•é¡Œ
            options.add_argument('--disable-gpu')        # ç¦ç”¨ GPU åŠ é€Ÿ
            
            # ä½¿ç”¨ä¿®æ­£å¾Œçš„ options åˆå§‹åŒ– Driver
            driver = uc.Chrome(options=options)
            driver.get(url)
            time.sleep(3) 

            # --------------------- Cloudflare Checkbox è™•ç†æ­¥é©Ÿ ---------------------
            handle_cloudflare_challenge(driver)
            # -------------------------------------------------------------------------

            # é»æ“Šç™»å…¥é€£çµä¸¦åŸ·è¡Œç™»å…¥ (é€™è£¡çš„ ID 'a_searchBtn' ä¼¼ä¹åŒæ™‚æ˜¯ç™»å…¥é€£çµå’ŒæŸ¥è©¢æŒ‰éˆ•)
            LOGIN_LINK_ID = "a_searchBtn"
            login_link = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.ID, LOGIN_LINK_ID)))
            login_link.click()
            login_success = perform_login(driver)
            
            if login_success:
                break
                
            if attempt < MAX_RETRIES:
                print(f"[{time.strftime('%H:%M:%S')}] ğŸ˜¥ ç¬¬ {attempt} æ¬¡åˆå§‹åŒ–/ç™»å…¥å¤±æ•—ï¼Œæ­£åœ¨é‡è©¦...")
            
        except Exception as e:
            print(f"[{time.strftime('%H:%M:%S')}] âŒ ç€è¦½å™¨æˆ–ç™»å…¥åˆå§‹åŒ–å¤±æ•—: {e}")
            if attempt < MAX_RETRIES:
                 print(f"[{time.strftime('%H:%M:%S')}] ğŸ˜¥ ç¬¬ {attempt} æ¬¡åˆå§‹åŒ–/ç™»å…¥å¤±æ•—ï¼Œæ­£åœ¨é‡è©¦...")


    if login_success and driver:
        # 3. åŸ·è¡Œä»»å‹™
        now = datetime.now()
        # æ³¨æ„ï¼šé€™è£¡çš„strftimeæ ¼å¼éœ€è¦æ ¹æ“šæ‚¨å¯¦éš›çš„ç³»çµ±/ç’°å¢ƒä¾†èª¿æ•´ï¼Œä»¥ç¢ºä¿èˆ‡æ‚¨åŸä¾†çš„æ•ˆæœä¸€è‡´
        # '%#m' å’Œ '%#d' åœ¨æŸäº›ç³»çµ± (å¦‚ Linux/GitHub Actions) ä¸Šå¯èƒ½ç„¡æ³•å·¥ä½œï¼Œä½†é€™è£¡ä¿æŒåŸæ¨£
        run_timestamp_for_file = now.strftime('%Y/%m/%d/%H') 
        run_scraping_task(driver, SEARCH_ITEMS, run_timestamp_for_file) 
    else:
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ˜¥ ç™»å…¥å¤±æ•—ï¼Œè·³éæœ¬æ¬¡çˆ¬èŸ²ä»»å‹™ã€‚")

    # 4. é—œé–‰ Driver
    if driver:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ§¹ ä»»å‹™çµæŸï¼Œæ­£åœ¨é—œé–‰ç€è¦½å™¨ Driver...")
        try:
            driver.quit() 
        except Exception:
            pass
    

# --- åŸ·è¡Œç¨‹å¼ç¢¼ (å–®æ¬¡åŸ·è¡Œ) ---
if __name__ == '__main__':
    target_url = "https://event.gnjoy.com.tw/RoZ/RoZ_ShopSearch" 
    print("==============================================")
    print(" Â  Â  Â ğŸ‰ çˆ¬èŸ²æ¸¬è©¦ç¨‹å¼å·²å•Ÿå‹• (å–®æ¬¡åŸ·è¡Œ) ğŸ‰")
    print("==============================================")
    # åŸ·è¡Œä¸€æ¬¡ä»»å‹™
    run_hourly_monitoring_cycle(target_url) 
    print("==============================================")
    print(" Â  Â  Â  Â  Â  âœ¨ ä»»å‹™åŸ·è¡Œå®Œç•¢ï¼Œç¨‹å¼çµæŸã€‚ âœ¨")
    print("==============================================")