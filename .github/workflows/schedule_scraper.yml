name: ğŸ•·ï¸ Hourly RO Scraper

# è¨­å®šè§¸ç™¼å™¨ï¼šæ¯å°æ™‚çš„ 0 åˆ†é˜åŸ·è¡Œ (ä¾‹å¦‚ 01:00, 02:00, ...) 
# æ³¨æ„ï¼šé€™èˆ‡æ‚¨ç¹ªåœ– Action çš„ 05 åˆ†éŒ¯é–‹ï¼Œé¿å…åŒæ™‚æ¨é€ã€‚
on:
  schedule:
    # CRON èªæ³•ï¼š'0 * * * *' ä»£è¡¨åœ¨æ¯å€‹å°æ™‚çš„ 0 åˆ†é˜åŸ·è¡Œ (UTC æ™‚é–“)
    - cron: '0 * * * *' 
      
  # å…è¨±æ‰‹å‹•è§¸ç™¼
  workflow_dispatch:

# æˆäºˆ GITHUB_TOKEN å¯«å…¥æ¬Šé™ï¼Œä»¥ä¾¿æäº¤æ–°çš„ CSV æ–‡ä»¶
permissions:
  contents: write

jobs:
  run_scraper:
    runs-on: ubuntu-latest
    
    # è¨­å®šç’°å¢ƒè®Šæ•¸ä¾› Python è…³æœ¬ä½¿ç”¨
    env:
      AUCTION_USERNAME: ${{ secrets.AUCTION_USERNAME }} # è«‹åœ¨ repo settings ä¸­è¨­å®š
      AUCTION_ID: ${{ secrets.AUCTION_ID }}             # è«‹åœ¨ repo settings ä¸­è¨­å®š

    steps:
      # 1. Checkout ç¨‹å¼ç¢¼
      - name: â¬‡ï¸ Checkout repository code
        uses: actions/checkout@v4
        with:
          # ç¢ºä¿ Action èƒ½æ‹‰å–å’Œæ¨é€
          token: ${{ secrets.GITHUB_TOKEN }} 

      # 2. è¨­å®š Python ç’°å¢ƒ
      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      # 3. å®‰è£ Python ä¾è³´ (åªä¿ç•™è…³æœ¬ä¸­å¯¦éš›ä½¿ç”¨çš„åº«)
      - name: âš™ï¸ Install dependencies (Scraper)
        run: |
          # pandas ç”¨æ–¼æ•¸æ“šåˆ†æï¼Œtabulate ç”¨æ–¼æ‰“å° Markdown è¡¨æ ¼
          pip install pandas tabulate
          # selenium å’Œ undetected-chromedriver ç”¨æ–¼ç€è¦½å™¨è‡ªå‹•åŒ–
          pip install undetected-chromedriver selenium

      # 4. é‹è¡Œ Python çˆ¬èŸ²è…³æœ¬
      - name: ğŸƒ Run main.py (Single Run)
        # ç”±æ–¼ main_scraper.py å·²ç¶“åŒ…å« Git æ¨é€é‚è¼¯ï¼Œé€™è£¡åªéœ€åŸ·è¡Œå®ƒ
        run: python main.py
        
      # æ³¨æ„ï¼šé€™è£¡ä¸éœ€è¦é¡å¤–çš„ git-auto-commit-actionï¼Œå› ç‚º main_scraper.py 
      # å…§å»ºçš„ auto_git_push å‡½æ•¸æœƒè™•ç† CSV æª”æ¡ˆçš„æäº¤å’Œæ¨é€åˆ° main åˆ†æ”¯ã€‚