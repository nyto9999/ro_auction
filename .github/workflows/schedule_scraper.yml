name: 🕷️ Hourly RO Scraper

# 設定觸發器：每小時的 0 分鐘執行 (例如 01:00, 02:00, ...) 
on:
  schedule:
    # CRON 語法：'0 * * * *' 代表在每個小時的 0 分鐘執行 (UTC 時間)
    - cron: '0 * * * *' 
      
  # 允許手動觸發
  workflow_dispatch:

# 授予 GITHUB_TOKEN 寫入權限，以便提交新的 CSV 文件
permissions:
  contents: write

jobs:
  run_scraper:
    runs-on: ubuntu-latest
    
    # 設定環境變數供 Python 腳本使用
    env:
      AUCTION_USERNAME: ${{ secrets.AUCTION_USERNAME }} # 請在 repo settings 中設定
      AUCTION_ID: ${{ secrets.AUCTION_ID }}             # 請在 repo settings 中設定

    steps:
      # 1. Checkout 程式碼
      - name: ⬇️ Checkout repository code
        uses: actions/checkout@v4
        with:
          # 確保 Action 能拉取和推送
          token: ${{ secrets.GITHUB_TOKEN }} 

      # 2. 設定 Python 環境
      - name: 🐍 Set up Python
        uses: actions/setup-python@v5
        with:
          # 【重要修正】將版本固定在 3.11，避免 Python 3.12+ 缺少 distutils 模組的錯誤。
          python-version: '3.11' 

      # 【新增步驟】：安裝必要的 Chrome 依賴庫
      - name: 🌐 Install required Chrome dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libnss3 libgconf-2-4 libasound2 libatk-bridge2.0-0 libgtk-3-0
          
      # 3. 安裝 Python 依賴
      - name: ⚙️ Install dependencies (Scraper)
        run: |
          pip install pandas tabulate
          pip install undetected-chromedriver selenium

      # 4. 運行 Python 爬蟲腳本
      - name: 🏃 Run main.py (Single Run)
        # 【修正】確定執行檔案是 main.py
        run: python main.py